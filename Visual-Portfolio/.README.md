
# AI Identity Replication Pipeline  
_Real Faces. Real Structure. Real Control._  

This portfolio showcases a fully offline, forensic-grade AI pipeline for replicating facial identity across diverse environments, lighting, and styles — using just a single source image.

We built this system to **recover, preserve, and stylize real human identity** using adaptive training and dynamic rendering — without reliance on cloud APIs, and without falling into stylization drift or feature hallucination.

---

## 🔬 Why This Matters

In most AI pipelines, faces become softened, idealized, or outright replaced with synthetic beauty norms. This system does the opposite:  
It **locks identity from real images**, and **renders consistent outputs** in new contexts while retaining structural integrity — bone geometry, eye spacing, jawline, skin age, and detail fidelity.

---

## 🧩 Pipeline Overview

1. Image Prep       → remove bg, detect face, crop, resize  
2. Augmentation     → rotation + scaled center crops  
3. Embedding        → 512-D reference vector for identity lock  
4. LoRA Training    → 4-phase adaptive convergence  
5. Seed Discovery   → cosine drift scored over multiple seeds  
6. Stylized Inference → 3-phase or 2-pass rendering  

Each stage is designed for minimal image input, zero cloud calls, and maximum identity fidelity.

---

### Visual Walkthrough

| Stage              | Description                                      |
|-------------------|--------------------------------------------------|
| 🔹 Input           | Public stock photo with lighting artifacts       |
| 🔹 Preprocessed    | Background removed, resized to 768x768, face-cropped |
| 🔹 Cropped Variant | Center crop for facial reinforcement (60%)      |
| 🔹 Identity Locked | Best result from cosine drift scoring loop      |
| 🔹 Stylized – Beach| Natural hair, lighting, and outdoor texture     |
| 🔹 Stylized – Rooftop| Urban scene, soft wind, sunset gradient      |
| 🔹 Stylized – Field| Golden hour, motion-blurred linen, 85mm lens    |

---

## 🧬 Identity Vector Embedding

Using a 512-D facial embedding network trained on real-world human geometry, we convert each prepared image into a numerical anchor. This vector is used to measure identity drift after generation.

```
drift = cosine(reference_embedding, generated_embedding)
```

We consider drift ≤ 0.18 to be “locked.”

---

## 🏋️ Training with Adaptive Convergence

Rather than rely on fixed step counts, we built a multi-phase training engine with real-time statistical convergence logic.

| Phase      | LR     | Alpha | Loss         | Optimizer |
|------------|--------|-------|--------------|-----------|
| COARSE     | 1e-4   | 8     | MSE          | AdamW     |
| MID        | 3e-5   | 4     | Huber        | AdamW     |
| MID_FINE   | 1e-6   | 2     | Charbonnier  | AdamP     |
| FINAL_FINE | 5e-7   | 1     | Charbonnier  | AdamP     |

### Convergence is detected via:
- Welford tracking of loss mean/variance  
- Sliding window slope analysis  
- Plateau detection (statistical p-value threshold)  

Example:  
> Exiting FINAL_FINE after 4 iterations (slope plateau detected).  
> LoRA saved to: /lora_weights/unet_lora

---

## 🎯 Seed Selection (Cosine Drift Verification)

After training, we pass the face back through rendering using different seed values, then compare each result to the original face vector. This ensures that the facial structure hasn't been lost or stylized away.

Example:
> Drift: 0.1621 | Seed: 1187891159  
> ✅ Saved: verify_seed_1187891159_drift_0.1621.png

---

## 🎨 Stylized Inference (3-Pass Rendering)

The final render is produced using a dynamic, GUI-driven image-to-image pipeline that:
- Locks identity with Phase 1 (LoRA)
- Applies scene prompts in Phase 2
- Stylizes gently in Phase 3
- Optionally blends back toward realism

| Phase     | Alpha | CFG  | Notes                            |
|-----------|--------|------|----------------------------------|
| Phase 1   | 1.0    | 5.8  | Identity lock                    |
| Phase 2   | 0.85   | 6.3  | Scene-specific composition       |
| Phase 3   | 0.90   | 6.8  | Final realism + Rescue (30%)     |

Example prompts:
- “Spa garden at dusk, candle-lit, 85mm, f/2.8”  
- “Urban rooftop, natural light, shallow depth”

---

## ⚡ Alternate Stylizer (2-Pass Export Mode)

For fast rendering or portrait exports, we use a simplified two-stage stylizer:
- Stable Diffusion-based anchor using LoRA  
- High-fidelity stylizer with realism base  

This version logs all prompt metadata and is ideal for final deliverables.

---

## ✅ Core Capabilities

- ✅ Identity locking from just one input photo  
- ✅ Fully offline — no external calls or dependencies  
- ✅ Multiple render options (dynamic, stylizer, inference)  
- ✅ Prompt-based pose and scene control  
- ✅ Cosine drift scoring for forensic verification  

---

## 🗣️ Ideal For...

- Forensic rendering & identity simulation  
- Photorealistic replication from limited samples  
- Stylized product or portrait generation  
- Projects requiring repeatable, controllable faces  

> This is not AI art.  
> It’s controlled identity replication.  
> No style drift. No feature loss. No hallucination.

---

## 🤝 Work With Me

Whether you’re looking to integrate identity-consistent rendering into your products, research, or creative pipeline — this framework is designed to plug in and scale.

📬 **Contact:** realtodd@yahoo.com  
🔗 **GitHub:** [https://github.com/Todd2112](https://github.com/Todd2112)

---

**We serve no aesthetic.  
We replicate truth.**
