# ğŸ¤– Reasoning AI Chatbot (Portfolio Demo)

Welcome to my **Reasoning AI Chatbot!**  
This app simulates how an intelligent assistant reasons through your questions â€” showing both its thought process and final answers.

---

## ğŸš€ Live Demo for HR Reviewers

[ğŸš€ Click here to try the app (Demo Mode only)](https://my-portfolio-reasoning-ai.streamlit.app)  
_**Tip:** Right-click or Ctrl+Click to open in a new tab!_

Demo Mode gives you a frictionless experience. It mimics how the AI would respond using logical reasoning â€” even without a large language model installed.

---

## ğŸ§  Full Mode (Local Use Only)

Want to run this chatbot with full AI power using **Ollama**?

1. **Install Ollama**  
   ğŸ‘‰ [Download here](https://ollama.com/download)

2. **Start the Ollama server:**
   ```bash
   ollama serve
3. **Pull a model (e.g., DeepSeek or LLaMA3):**
   ```bash
   ollama pull deepseek-coder:latest
4. **or:**
   ```bash
   ollama pull llama3
5. **Run the Streamlit app:**
   ```bash
   streamlit run streamlit-app.py

In the app, switch to "Full Mode" using the toggle at the top to enable actual AI-based reasoning.
Now your chatbot is connected to a real local LLM!

ğŸ“¦ Dependencies

Make sure these are installed in your Python environment:

**requirements.txt:**
<pre>
```plaintext
streamlit
requests
</pre>

**Install them with:**
```bash
pip install -r requirements.txt
```

ğŸ§‘â€ğŸ’» For Developers
**Clone the repo and run it locally:**
```bash
git clone https://github.com/Todd2112/My-Portfolio.git
cd My-Portfolio
pip install -r requirements.txt
streamlit run streamlit-app.py
```

ğŸ›  Features
âœ… Toggle between Demo Mode and Full Mode
ğŸ§  Reasoning simulation in the browser (no LLM needed)
ğŸ”Œ Local LLM support via Ollama
ğŸ“± Built with Streamlit â€” easy to run and customize


